{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib  # For saving model in .pkl format\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2Ô∏è‚É£ Load the final preprocessed dataset\n",
    "df = pd.read_csv(\"D:/FYP/data/datasets/final_dataset_02.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3Ô∏è‚É£ Separate features and target\n",
    "X = df.drop(columns=['label'])  # Features\n",
    "y = df['label'].astype(int)     # Target (0 = Normal, 1 = Attack)\n",
    "\n",
    "# 4Ô∏è‚É£ Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ Convert data to DMatrix (XGBoost's optimized data format)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.99823\n",
      "[1]\teval-auc:1.00000\n",
      "[2]\teval-auc:1.00000\n",
      "[3]\teval-auc:0.99999\n",
      "[4]\teval-auc:1.00000\n",
      "[5]\teval-auc:1.00000\n",
      "[6]\teval-auc:1.00000\n",
      "[7]\teval-auc:1.00000\n",
      "[8]\teval-auc:1.00000\n",
      "[9]\teval-auc:1.00000\n",
      "[10]\teval-auc:1.00000\n",
      "[11]\teval-auc:1.00000\n",
      "[12]\teval-auc:1.00000\n",
      "[13]\teval-auc:1.00000\n",
      "[14]\teval-auc:1.00000\n",
      "[15]\teval-auc:1.00000\n",
      "[16]\teval-auc:1.00000\n",
      "[17]\teval-auc:1.00000\n",
      "[18]\teval-auc:1.00000\n",
      "[19]\teval-auc:1.00000\n",
      "[20]\teval-auc:1.00000\n",
      "[21]\teval-auc:1.00000\n",
      "[22]\teval-auc:1.00000\n",
      "[23]\teval-auc:1.00000\n",
      "[24]\teval-auc:1.00000\n",
      "[25]\teval-auc:1.00000\n",
      "[26]\teval-auc:1.00000\n",
      "[27]\teval-auc:1.00000\n",
      "[28]\teval-auc:1.00000\n",
      "[29]\teval-auc:1.00000\n",
      "[30]\teval-auc:1.00000\n",
      "[31]\teval-auc:1.00000\n",
      "[32]\teval-auc:1.00000\n",
      "[33]\teval-auc:1.00000\n",
      "[34]\teval-auc:1.00000\n",
      "[35]\teval-auc:1.00000\n",
      "[36]\teval-auc:1.00000\n",
      "[37]\teval-auc:1.00000\n",
      "[38]\teval-auc:1.00000\n",
      "[39]\teval-auc:1.00000\n",
      "[40]\teval-auc:1.00000\n",
      "[41]\teval-auc:1.00000\n",
      "[42]\teval-auc:1.00000\n",
      "[43]\teval-auc:1.00000\n",
      "[44]\teval-auc:1.00000\n",
      "[45]\teval-auc:1.00000\n",
      "[46]\teval-auc:1.00000\n",
      "[47]\teval-auc:1.00000\n",
      "[48]\teval-auc:1.00000\n",
      "[49]\teval-auc:1.00000\n",
      "[50]\teval-auc:1.00000\n",
      "[51]\teval-auc:1.00000\n",
      "[52]\teval-auc:1.00000\n",
      "[53]\teval-auc:1.00000\n",
      "[54]\teval-auc:1.00000\n",
      "[55]\teval-auc:1.00000\n",
      "[56]\teval-auc:1.00000\n",
      "[57]\teval-auc:1.00000\n",
      "[58]\teval-auc:1.00000\n",
      "[59]\teval-auc:1.00000\n",
      "[60]\teval-auc:1.00000\n",
      "[61]\teval-auc:1.00000\n",
      "[62]\teval-auc:1.00000\n",
      "[63]\teval-auc:1.00000\n",
      "[64]\teval-auc:1.00000\n",
      "[65]\teval-auc:1.00000\n",
      "[66]\teval-auc:1.00000\n",
      "[67]\teval-auc:1.00000\n",
      "[68]\teval-auc:1.00000\n",
      "[69]\teval-auc:1.00000\n",
      "[70]\teval-auc:1.00000\n",
      "[71]\teval-auc:1.00000\n",
      "[72]\teval-auc:1.00000\n",
      "[73]\teval-auc:1.00000\n",
      "[74]\teval-auc:1.00000\n",
      "[75]\teval-auc:1.00000\n",
      "[76]\teval-auc:1.00000\n",
      "[77]\teval-auc:1.00000\n",
      "[78]\teval-auc:1.00000\n",
      "[79]\teval-auc:1.00000\n",
      "[80]\teval-auc:1.00000\n",
      "[81]\teval-auc:1.00000\n",
      "[82]\teval-auc:1.00000\n",
      "[83]\teval-auc:1.00000\n",
      "[84]\teval-auc:1.00000\n",
      "[85]\teval-auc:1.00000\n",
      "[86]\teval-auc:1.00000\n",
      "[87]\teval-auc:1.00000\n",
      "[88]\teval-auc:1.00000\n",
      "[89]\teval-auc:1.00000\n",
      "[90]\teval-auc:1.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6Ô∏è‚É£ Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'auc',           # Metric for evaluation\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# 7Ô∏è‚É£ Train the model with early stopping\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=300,            # Equivalent to n_estimators\n",
    "    evals=[(dtest, 'eval')],        # Validation set\n",
    "    early_stopping_rounds=50,       # Early stopping\n",
    "    verbose_eval=True               # Print progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8Ô∏è‚É£ Make predictions (returns probabilities by default)\n",
    "y_pred_proba = model.predict(dtest)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert to binary classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Accuracy: 100.0 %\n",
      "\n",
      "üìä Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13386\n",
      "           1       1.00      1.00      1.00     13385\n",
      "\n",
      "    accuracy                           1.00     26771\n",
      "   macro avg       1.00      1.00      1.00     26771\n",
      "weighted avg       1.00      1.00      1.00     26771\n",
      "\n",
      "\n",
      "üîç Confusion Matrix:\n",
      " [[13386     0]\n",
      " [    0 13385]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9Ô∏è‚É£ Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"‚úÖ Model Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
    "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nüîç Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trained XGBoost model saved successfully: models/trained_models/xgboost_native_model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üîü Save trained model in .pkl format using joblib\n",
    "os.makedirs(\"/trained_models\", exist_ok=True)  # Create directory if it doesn't exist\n",
    "joblib.dump(model, \"D:/FYP/models/trained_models/xgboost_native_model.pkl\")\n",
    "print(\"‚úÖ Trained XGBoost model saved successfully: models/trained_models/xgboost_native_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
